{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T08:45:32.479142Z",
     "start_time": "2019-09-29T08:45:32.233067Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "TCEH7UbCkTv_"
   },
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T08:45:32.561318Z",
     "start_time": "2019-09-29T08:45:32.481202Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "bkGglN-vkTph",
    "outputId": "11b85f53-6171-4d63-a46f-312d02781e2d"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "def load_data():\n",
    "    print(\"Loading dataset\")\n",
    "\n",
    "    from glob import glob\n",
    "    filenames_neg = sorted(glob(op.join('data', 'imdb1', 'neg', '*.txt')))\n",
    "    filenames_pos = sorted(glob(op.join('data', 'imdb1', 'pos', '*.txt')))\n",
    "\n",
    "    texts_neg = [open(f).read() for f in filenames_neg]\n",
    "    texts_pos = [open(f).read() for f in filenames_pos]\n",
    "    texts = texts_neg + texts_pos\n",
    "    y = np.ones(len(texts), dtype=np.int)\n",
    "    y[:len(texts_neg)] = 0.\n",
    "\n",
    "\n",
    "    print(\"%d documents\" % len(texts))\n",
    "    return texts, y\n",
    "\n",
    "def shuffle_data(X, y):\n",
    "    indices = list(range(len(y)))\n",
    "    np.random.shuffle(indices)    \n",
    "    y = y[indices]\n",
    "    X = X[indices]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "2000 documents\n"
     ]
    }
   ],
   "source": [
    "texts, y = load_data()\n",
    "texts, y = shuffle_data(np.array(texts), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1htbfPDkzjx4"
   },
   "source": [
    "\n",
    "# Implementation of the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mg87IEOB0Exc"
   },
   "source": [
    "## Count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T08:49:29.102753Z",
     "start_time": "2019-09-29T08:49:29.096121Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1898XPru6C9m",
    "outputId": "a3c452ca-cf1e-4cc8-80c1-59c58bb99230"
   },
   "outputs": [],
   "source": [
    "# Read stop word\n",
    "def read_stop_words(remove_punc=False):\n",
    "    filepath = \"data/english.stop\"\n",
    "    stop_words = []\n",
    "    with open(filepath) as fp:\n",
    "        line = fp.readline()\n",
    "        cnt = 1\n",
    "        while line:\n",
    "            line = line.strip()\n",
    "            if remove_punc:\n",
    "                line = re.sub(r\"[^a-z]\", \"\", line) #remove punctuation            \n",
    "            stop_words.append(line) \n",
    "            cnt += 1\n",
    "            line = fp.readline()\n",
    "    print(\"There are\", cnt, \"stop words\")\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T08:49:30.116339Z",
     "start_time": "2019-09-29T08:49:30.108533Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "0DlwYt-akr5J"
   },
   "outputs": [],
   "source": [
    "def tokenize(s):    \n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"[^a-z]\", \" \", s) # remove punctuation \n",
    "    ws = re.compile(r\"\\s+\").split(s)    \n",
    "    return [w for w in ws if len(w) > 0]\n",
    "\n",
    "def count_words(texts, stop_words=[]):\n",
    "    \"\"\"Vectorize text : return count of each word in the text snippets\n",
    "\n",
    "    Parametersl\n",
    "    ----------\n",
    "    texts : list of str\n",
    "        The texts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vocabulary : dict\n",
    "        A dictionary that points to an index in counts for each word.\n",
    "    counts : ndarray, shape (n_samples, n_features)\n",
    "        The counts of each word in each text.\n",
    "        n_samples == number of documents.\n",
    "        n_features == number of words in vocabulary.\n",
    "    \"\"\"\n",
    "    \n",
    "    words = set()\n",
    "    for text in texts:      \n",
    "        ws = tokenize(text)      \n",
    "        for w in ws:   \n",
    "            if w not in stop_words:\n",
    "                words.add(w)\n",
    "    \n",
    "    vocabulary = dict()\n",
    "    for i, word in enumerate(words):\n",
    "        vocabulary[word] = i\n",
    "        \n",
    "    n_features = len(vocabulary)\n",
    "    print(\"Number of words in vocabulary:\", n_features)\n",
    "    counts = np.zeros((len(texts), n_features))\n",
    "    for i, text in enumerate(texts):\n",
    "        ws = tokenize(text)\n",
    "        for word in ws: \n",
    "            if word in vocabulary:\n",
    "                word_index = vocabulary[word]\n",
    "                counts[i, word_index] += 1\n",
    "    return vocabulary, counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T08:49:48.168988Z",
     "start_time": "2019-09-29T08:49:31.110270Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "56J5ljlslOAE",
    "outputId": "ab5e02b5-e7c4-48c3-c1f4-1187df1e4087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 572 stop words\n",
      "Number of words in vocabulary: 38395\n",
      "X shape (2000, 38395)\n"
     ]
    }
   ],
   "source": [
    "stop_words = read_stop_words(remove_punc=True)\n",
    "vocabulary, X = count_words(texts, stop_words=stop_words)\n",
    "print(\"X shape\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T08:51:06.746491Z",
     "start_time": "2019-09-29T08:51:06.734387Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "NNrNdrpYl09P"
   },
   "outputs": [],
   "source": [
    "class NB(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):        \n",
    "        self.prior = []\n",
    "        self.likelihood = []\n",
    "        self.classes = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        prior = [0] * len(self.classes)\n",
    "        N = len(y)\n",
    "        likelihood = np.zeros((X.shape[1], len(self.classes)))\n",
    "        for i, c in enumerate(self.classes):\n",
    "            prior[i] = np.sum(y == c) / N \n",
    "            X_class = np.sum(X[y == c], axis=0) # count number of occurences of token in each class        \n",
    "            likelihood[:, i] = X_class        \n",
    "        likelihood = likelihood + 1\n",
    "        likelihood = likelihood / np.sum(likelihood, axis=0).reshape(1, -1)\n",
    "          \n",
    "        self.prior = prior\n",
    "        self.likelihood = likelihood\n",
    "                    \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):                \n",
    "        scores = X @ np.log(self.likelihood) + np.log(self.prior).reshape(1, -1)\n",
    "        y_pred = np.argmax(scores, axis=1)        \n",
    "        return [self.classes[i] for i in y_pred]\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUADJeNM5mmU"
   },
   "source": [
    "# Performance evaluation and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_pred):\n",
    "    return np.mean(y == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBL_mXf11OHJ"
   },
   "outputs": [],
   "source": [
    "def cross_validation(clf, X, y, n_folds=5):\n",
    "    interval = len(y) // n_folds\n",
    "    scores = []\n",
    "    for i in range(n_folds):\n",
    "        start = int(i * interval)\n",
    "        end = int((i + 1) * interval)\n",
    "\n",
    "        X_test = X[start:end]\n",
    "        y_test = y[start:end]\n",
    "        X_train = np.concatenate([X[:start], X[end:]])\n",
    "        y_train = np.concatenate([y[:start], y[end:]])\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        score = accuracy(y_pred, y_test)\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My implementation of NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C2J6qCuI28jk",
    "outputId": "7fe798dd-aec3-450f-c93a-85bce19aa6de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.805, 0.8075, 0.8025, 0.8075, 0.785] 0.8015000000000001\n"
     ]
    }
   ],
   "source": [
    "nb = NB()\n",
    "scores = cross_validation(nb, X, y)\n",
    "print(scores, np.mean(scores)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NScnoJcN3sue",
    "outputId": "994aa102-1628-4606-a129-f2aa82dd035d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.805, 0.8075, 0.8025, 0.8075, 0.785] 0.8015000000000001\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "scores = cross_validation(mnb, X, y)\n",
    "print(scores, np.mean(scores)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use sklearn and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipeline(clf_name, clf, texts, y, analyzer):\n",
    "    mnb_pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', # only applied if analyzer = 'word'\n",
    "                                 analyzer=analyzer, \n",
    "                                 ngram_range=(1, 2))), # allow bigrams\n",
    "        ('clf', clf),\n",
    "    ])\n",
    "    scores = cross_validation(mnb_pipeline, texts, y)\n",
    "    print(clf_name + \":\", scores,\"- mean accuracy:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(analyzer, texts, y):\n",
    "    \n",
    "    nb = NB()\n",
    "    evaluate_pipeline(\"My NB\", nb, texts, y, analyzer)\n",
    "\n",
    "    mnb = MultinomialNB()\n",
    "    evaluate_pipeline(\"Multinomial NB\", mnb, texts, y, analyzer)\n",
    "\n",
    "    lsvc = LinearSVC(max_iter=500)\n",
    "    evaluate_pipeline(\"Linear SVC\", lsvc, texts, y, analyzer)\n",
    "\n",
    "    reg = LogisticRegression(solver='lbfgs')\n",
    "    evaluate_pipeline(\"Logistic Regression\", reg, texts, y, analyzer)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=20)\n",
    "    evaluate_pipeline(\"Random forest\", rf, texts, y, analyzer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My NB: [0.8225, 0.815, 0.7775, 0.81, 0.7825] - mean accuracy: 0.8015000000000001\n",
      "Multinomial NB: [0.8225, 0.815, 0.7775, 0.81, 0.7825] - mean accuracy: 0.8015000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/edxml/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC: [0.8325, 0.8275, 0.8425, 0.8375, 0.8175] - mean accuracy: 0.8315000000000001\n",
      "Logistic Regression: [0.83, 0.8275, 0.8375, 0.845, 0.8325] - mean accuracy: 0.8344999999999999\n",
      "Random forest: [0.7175, 0.7325, 0.78, 0.6975, 0.725] - mean accuracy: 0.7305\n"
     ]
    }
   ],
   "source": [
    "evaluate('word', texts, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My NB: [0.68, 0.7175, 0.68, 0.6975, 0.6675] - mean accuracy: 0.6885000000000001\n",
      "Multinomial NB: [0.68, 0.7175, 0.68, 0.6975, 0.6675] - mean accuracy: 0.6885000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/edxml/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC: [0.72, 0.62, 0.645, 0.69, 0.63] - mean accuracy: 0.6609999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/edxml/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/miniconda3/envs/edxml/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/miniconda3/envs/edxml/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/miniconda3/envs/edxml/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/miniconda3/envs/edxml/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: [0.7225, 0.71, 0.655, 0.675, 0.6775] - mean accuracy: 0.6880000000000001\n",
      "Random forest: [0.575, 0.63, 0.615, 0.615, 0.57] - mean accuracy: 0.601\n"
     ]
    }
   ],
   "source": [
    "evaluate('char', texts, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "2000 documents\n"
     ]
    }
   ],
   "source": [
    "texts, y = load_data()\n",
    "texts, y = shuffle_data(np.array(texts), y)\n",
    "\n",
    "new_texts = []\n",
    "for i, text in enumerate(texts):\n",
    "    tokens = tokenize(text)\n",
    "    token_str = \" \".join([stemmer.stem(token) for token in tokens if len(token) > 0 and token not in stop_words])\n",
    "    new_texts.append(token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My NB: [0.8025, 0.83, 0.7875, 0.8075, 0.765] - mean accuracy: 0.7985\n",
      "Multinomial NB: [0.8025, 0.83, 0.7875, 0.8075, 0.765] - mean accuracy: 0.7985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/edxml/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC: [0.8175, 0.8375, 0.8175, 0.8125, 0.8225] - mean accuracy: 0.8215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/edxml/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: [0.835, 0.8425, 0.8075, 0.81, 0.84] - mean accuracy: 0.827\n",
      "Random forest: [0.7375, 0.7375, 0.7525, 0.71, 0.6925] - mean accuracy: 0.726\n"
     ]
    }
   ],
   "source": [
    "evaluate('word', new_texts, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: POS tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "2000 documents\n"
     ]
    }
   ],
   "source": [
    "texts, y = load_data()\n",
    "texts, y = shuffle_data(np.array(texts), y)\n",
    "\n",
    "keeps = [\"NN\", \"NNS\", 'NNP', 'NNPS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'RB', 'RBR', 'RBS', 'JJ', 'JJR', 'JJS']\n",
    "\n",
    "new_texts = []\n",
    "for i, text in enumerate(texts):\n",
    "    tokens = tokenize(text)\n",
    "    token_with_tags = nltk.pos_tag(tokens)\n",
    "    filtered_token_with_tags = filter(lambda x: x[1] in keeps, token_with_tags) # keep only noun, adverbs, verb, adj\n",
    "    filtered_tokens = map(lambda x: x[0], filtered_token_with_tags)\n",
    "    new_texts.append(\" \".join(filtered_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My NB: [0.845, 0.775, 0.785, 0.7775, 0.82] - mean accuracy: 0.8005000000000001\n",
      "Multinomial NB: [0.845, 0.775, 0.785, 0.7775, 0.82] - mean accuracy: 0.8005000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/edxml/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC: [0.825, 0.83, 0.83, 0.825, 0.845] - mean accuracy: 0.8309999999999998\n",
      "Logistic Regression: [0.835, 0.835, 0.8425, 0.81, 0.86] - mean accuracy: 0.8365\n",
      "Random forest: [0.7475, 0.74, 0.74, 0.715, 0.7025] - mean accuracy: 0.729\n"
     ]
    }
   ],
   "source": [
    "# pos_tag - keep only noun, adverbs, verb, adj\n",
    "evaluate('word', new_texts, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My NB: [0.8425, 0.7675, 0.7925, 0.7775, 0.82] - mean accuracy: 0.7999999999999999\n",
      "Multinomial NB: [0.8425, 0.7675, 0.7925, 0.7775, 0.82] - mean accuracy: 0.7999999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/edxml/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC: [0.825, 0.8325, 0.8475, 0.82, 0.8525] - mean accuracy: 0.8355\n",
      "Logistic Regression: [0.835, 0.8325, 0.8475, 0.8175, 0.86] - mean accuracy: 0.8385\n",
      "Random forest: [0.725, 0.7325, 0.73, 0.7275, 0.735] - mean accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Without pos tag\n",
    "evaluate('word', texts, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLPlab1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
